[2022-08-06 19:36:00,961] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [queued]>
[2022-08-06 19:36:00,981] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [queued]>
[2022-08-06 19:36:00,982] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:36:00,982] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:36:00,982] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:36:01,006] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-02 00:00:00+00:00
[2022-08-06 19:36:01,017] {standard_task_runner.py:52} INFO - Started process 135 to run task
[2022-08-06 19:36:01,021] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-02T00:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmphz3aakkf', '--error-file', '/tmp/tmpfg5wd9y_']
[2022-08-06 19:36:01,021] {standard_task_runner.py:80} INFO - Job 17: Subtask thrid_task
[2022-08-06 19:36:01,115] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:36:01,229] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T00:00:00+00:00
[2022-08-06 19:36:01,230] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:36:01,231] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 19:36:01,246] {subprocess.py:85} INFO - Output:
[2022-08-06 19:36:01,248] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 19:36:01,248] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:36:01,372] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210802T000000, start_date=20220806T193600, end_date=20220806T193601
[2022-08-06 19:36:01,404] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:36:01,468] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:49:57,811] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [queued]>
[2022-08-06 21:49:57,832] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [queued]>
[2022-08-06 21:49:57,832] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:49:57,832] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:49:57,832] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:49:57,854] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-02 00:00:00+00:00
[2022-08-06 21:49:57,872] {standard_task_runner.py:52} INFO - Started process 322 to run task
[2022-08-06 21:49:57,880] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-02T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmptbkpu3vk', '--error-file', '/tmp/tmp56u7bf08']
[2022-08-06 21:49:57,880] {standard_task_runner.py:80} INFO - Job 15: Subtask thrid_task
[2022-08-06 21:49:57,977] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:49:58,084] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T00:00:00+00:00
[2022-08-06 21:49:58,085] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:49:58,086] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:49:58,100] {subprocess.py:85} INFO - Output:
[2022-08-06 21:49:58,102] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:49:58,102] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:49:58,165] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210802T000000, start_date=20220806T214957, end_date=20220806T214958
[2022-08-06 21:49:58,212] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:49:58,263] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:55:27,954] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [queued]>
[2022-08-06 21:55:27,971] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [queued]>
[2022-08-06 21:55:27,971] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:55:27,971] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:55:27,972] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:55:27,992] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-02 00:00:00+00:00
[2022-08-06 21:55:28,000] {standard_task_runner.py:52} INFO - Started process 129 to run task
[2022-08-06 21:55:28,006] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-02T00:00:00+00:00', '--job-id', '18', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpf_4b01yp', '--error-file', '/tmp/tmpj1w4hk19']
[2022-08-06 21:55:28,006] {standard_task_runner.py:80} INFO - Job 18: Subtask thrid_task
[2022-08-06 21:55:28,151] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:55:28,273] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T00:00:00+00:00
[2022-08-06 21:55:28,274] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:55:28,274] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:55:28,290] {subprocess.py:85} INFO - Output:
[2022-08-06 21:55:28,292] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:55:28,292] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:55:28,352] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210802T000000, start_date=20220806T215527, end_date=20220806T215528
[2022-08-06 21:55:28,380] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:55:28,425] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:10:26,559] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [queued]>
[2022-08-06 22:10:26,574] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [queued]>
[2022-08-06 22:10:26,575] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:10:26,575] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:10:26,575] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:10:26,596] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-02 00:00:00+00:00
[2022-08-06 22:10:26,602] {standard_task_runner.py:52} INFO - Started process 126 to run task
[2022-08-06 22:10:26,605] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-02T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmprcn0t44f', '--error-file', '/tmp/tmpu1t_h4bo']
[2022-08-06 22:10:26,605] {standard_task_runner.py:80} INFO - Job 13: Subtask thrid_task
[2022-08-06 22:10:26,686] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:10:26,811] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T00:00:00+00:00
[2022-08-06 22:10:26,812] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:10:26,813] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:10:26,836] {subprocess.py:85} INFO - Output:
[2022-08-06 22:10:26,836] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:10:26,836] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:10:26,886] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210802T000000, start_date=20220806T221026, end_date=20220806T221026
[2022-08-06 22:10:26,940] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:10:26,982] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:18:14,853] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [queued]>
[2022-08-06 22:18:14,868] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [queued]>
[2022-08-06 22:18:14,868] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:18:14,868] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:18:14,868] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:18:14,884] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-02 00:00:00+00:00
[2022-08-06 22:18:14,891] {standard_task_runner.py:52} INFO - Started process 146 to run task
[2022-08-06 22:18:14,894] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-02T00:00:00+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmplgmk2ude', '--error-file', '/tmp/tmpgnbacb09']
[2022-08-06 22:18:14,894] {standard_task_runner.py:80} INFO - Job 19: Subtask thrid_task
[2022-08-06 22:18:14,974] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [running]> on host ed53bde1c44a
[2022-08-06 22:18:15,102] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T00:00:00+00:00
[2022-08-06 22:18:15,103] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:18:15,104] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:18:15,120] {subprocess.py:85} INFO - Output:
[2022-08-06 22:18:15,123] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:18:15,123] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:18:15,165] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210802T000000, start_date=20220806T221814, end_date=20220806T221815
[2022-08-06 22:18:15,227] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:18:15,275] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:21:48,205] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [queued]>
[2022-08-06 22:21:48,221] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [queued]>
[2022-08-06 22:21:48,221] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:21:48,221] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:21:48,221] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:21:48,237] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-02 00:00:00+00:00
[2022-08-06 22:21:48,244] {standard_task_runner.py:52} INFO - Started process 168 to run task
[2022-08-06 22:21:48,247] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-02T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpwrgtilwr', '--error-file', '/tmp/tmpox3tnu1t']
[2022-08-06 22:21:48,247] {standard_task_runner.py:80} INFO - Job 13: Subtask thrid_task
[2022-08-06 22:21:48,330] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-02T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:21:48,465] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-02T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-02T00:00:00+00:00
[2022-08-06 22:21:48,466] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:21:48,471] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:21:48,490] {subprocess.py:85} INFO - Output:
[2022-08-06 22:21:48,493] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:21:48,493] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:21:48,544] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210802T000000, start_date=20220806T222148, end_date=20220806T222148
[2022-08-06 22:21:48,579] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:21:48,623] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
