[2022-08-06 19:36:06,902] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [queued]>
[2022-08-06 19:36:06,917] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [queued]>
[2022-08-06 19:36:06,917] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:36:06,917] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:36:06,917] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:36:06,935] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-12 00:00:00+00:00
[2022-08-06 19:36:06,941] {standard_task_runner.py:52} INFO - Started process 220 to run task
[2022-08-06 19:36:06,944] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-12T00:00:00+00:00', '--job-id', '44', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpxc8erz59', '--error-file', '/tmp/tmpfh_s357s']
[2022-08-06 19:36:06,944] {standard_task_runner.py:80} INFO - Job 44: Subtask thrid_task
[2022-08-06 19:36:07,021] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:36:07,129] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-12T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-12T00:00:00+00:00
[2022-08-06 19:36:07,130] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:36:07,130] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 19:36:07,144] {subprocess.py:85} INFO - Output:
[2022-08-06 19:36:07,146] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 19:36:07,146] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:36:07,184] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210812T000000, start_date=20220806T193606, end_date=20220806T193607
[2022-08-06 19:36:07,236] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:36:07,273] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:50:02,681] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [queued]>
[2022-08-06 21:50:02,699] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [queued]>
[2022-08-06 21:50:02,699] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:50:02,699] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:50:02,699] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:50:02,720] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-12 00:00:00+00:00
[2022-08-06 21:50:02,727] {standard_task_runner.py:52} INFO - Started process 419 to run task
[2022-08-06 21:50:02,731] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-12T00:00:00+00:00', '--job-id', '46', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpnf1rdmw1', '--error-file', '/tmp/tmphnv8ne2_']
[2022-08-06 21:50:02,731] {standard_task_runner.py:80} INFO - Job 46: Subtask thrid_task
[2022-08-06 21:50:02,805] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:50:02,901] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-12T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-12T00:00:00+00:00
[2022-08-06 21:50:02,902] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:50:02,902] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:50:02,920] {subprocess.py:85} INFO - Output:
[2022-08-06 21:50:02,921] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:50:02,922] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:50:02,959] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210812T000000, start_date=20220806T215002, end_date=20220806T215002
[2022-08-06 21:50:02,982] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:50:03,036] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:55:33,602] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [queued]>
[2022-08-06 21:55:33,624] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [queued]>
[2022-08-06 21:55:33,625] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:55:33,625] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:55:33,625] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:55:33,648] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-12 00:00:00+00:00
[2022-08-06 21:55:33,656] {standard_task_runner.py:52} INFO - Started process 225 to run task
[2022-08-06 21:55:33,659] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-12T00:00:00+00:00', '--job-id', '47', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpy6yjva_i', '--error-file', '/tmp/tmp7f_gldja']
[2022-08-06 21:55:33,661] {standard_task_runner.py:80} INFO - Job 47: Subtask thrid_task
[2022-08-06 21:55:33,746] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:55:33,832] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-12T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-12T00:00:00+00:00
[2022-08-06 21:55:33,833] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:55:33,833] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:55:33,849] {subprocess.py:85} INFO - Output:
[2022-08-06 21:55:33,851] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:55:33,852] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:55:33,889] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210812T000000, start_date=20220806T215533, end_date=20220806T215533
[2022-08-06 21:55:33,952] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:55:33,992] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:10:32,347] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [queued]>
[2022-08-06 22:10:32,366] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [queued]>
[2022-08-06 22:10:32,366] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:10:32,367] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:10:32,367] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:10:32,389] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-12 00:00:00+00:00
[2022-08-06 22:10:32,396] {standard_task_runner.py:52} INFO - Started process 216 to run task
[2022-08-06 22:10:32,399] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-12T00:00:00+00:00', '--job-id', '44', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp5oyl_2lo', '--error-file', '/tmp/tmpmksgyq3q']
[2022-08-06 22:10:32,400] {standard_task_runner.py:80} INFO - Job 44: Subtask thrid_task
[2022-08-06 22:10:32,484] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:10:32,598] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-12T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-12T00:00:00+00:00
[2022-08-06 22:10:32,599] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:10:32,600] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:10:32,619] {subprocess.py:85} INFO - Output:
[2022-08-06 22:10:32,620] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:10:32,620] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:10:32,653] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210812T000000, start_date=20220806T221032, end_date=20220806T221032
[2022-08-06 22:10:32,691] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:10:32,724] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:18:19,805] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [queued]>
[2022-08-06 22:18:19,817] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [queued]>
[2022-08-06 22:18:19,817] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:18:19,817] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:18:19,817] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:18:19,835] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-12 00:00:00+00:00
[2022-08-06 22:18:19,844] {standard_task_runner.py:52} INFO - Started process 229 to run task
[2022-08-06 22:18:19,850] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-12T00:00:00+00:00', '--job-id', '44', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpia7_xdxb', '--error-file', '/tmp/tmpynl3oh5i']
[2022-08-06 22:18:19,851] {standard_task_runner.py:80} INFO - Job 44: Subtask thrid_task
[2022-08-06 22:18:19,931] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [running]> on host ed53bde1c44a
[2022-08-06 22:18:20,039] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-12T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-12T00:00:00+00:00
[2022-08-06 22:18:20,040] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:18:20,041] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:18:20,053] {subprocess.py:85} INFO - Output:
[2022-08-06 22:18:20,054] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:18:20,055] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:18:20,087] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210812T000000, start_date=20220806T221819, end_date=20220806T221820
[2022-08-06 22:18:20,139] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:18:20,172] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:21:53,480] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [queued]>
[2022-08-06 22:21:53,502] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [queued]>
[2022-08-06 22:21:53,502] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:21:53,502] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:21:53,502] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:21:53,522] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-12 00:00:00+00:00
[2022-08-06 22:21:53,580] {standard_task_runner.py:52} INFO - Started process 263 to run task
[2022-08-06 22:21:53,583] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-12T00:00:00+00:00', '--job-id', '44', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpkub8y9bv', '--error-file', '/tmp/tmpsrxy97_w']
[2022-08-06 22:21:53,584] {standard_task_runner.py:80} INFO - Job 44: Subtask thrid_task
[2022-08-06 22:21:53,657] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-12T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:21:53,752] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-12T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-12T00:00:00+00:00
[2022-08-06 22:21:53,753] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:21:53,753] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:21:53,766] {subprocess.py:85} INFO - Output:
[2022-08-06 22:21:53,768] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:21:53,768] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:21:53,806] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210812T000000, start_date=20220806T222153, end_date=20220806T222153
[2022-08-06 22:21:53,835] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:21:53,866] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
