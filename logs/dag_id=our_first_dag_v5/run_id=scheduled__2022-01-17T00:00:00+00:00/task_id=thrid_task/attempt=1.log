[2022-08-06 19:37:46,788] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [queued]>
[2022-08-06 19:37:46,809] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [queued]>
[2022-08-06 19:37:46,809] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:46,809] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:37:46,809] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:46,832] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-17 00:00:00+00:00
[2022-08-06 19:37:46,840] {standard_task_runner.py:52} INFO - Started process 1718 to run task
[2022-08-06 19:37:46,843] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-17T00:00:00+00:00', '--job-id', '518', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpbrwlpsbo', '--error-file', '/tmp/tmp7fmdb8c8']
[2022-08-06 19:37:46,843] {standard_task_runner.py:80} INFO - Job 518: Subtask thrid_task
[2022-08-06 19:37:46,945] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:37:47,046] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-17T00:00:00+00:00
[2022-08-06 19:37:47,047] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:37:47,048] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 19:37:47,062] {subprocess.py:85} INFO - Output:
[2022-08-06 19:37:47,064] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 19:37:47,064] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:37:47,100] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220117T000000, start_date=20220806T193746, end_date=20220806T193747
[2022-08-06 19:37:47,136] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:37:47,173] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:51:41,101] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [queued]>
[2022-08-06 21:51:41,117] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [queued]>
[2022-08-06 21:51:41,117] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:41,117] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:51:41,117] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:41,139] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-17 00:00:00+00:00
[2022-08-06 21:51:41,147] {standard_task_runner.py:52} INFO - Started process 1921 to run task
[2022-08-06 21:51:41,151] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-17T00:00:00+00:00', '--job-id', '522', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp0mjf6e71', '--error-file', '/tmp/tmp2bquz9aw']
[2022-08-06 21:51:41,151] {standard_task_runner.py:80} INFO - Job 522: Subtask thrid_task
[2022-08-06 21:51:41,259] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:51:41,380] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-17T00:00:00+00:00
[2022-08-06 21:51:41,382] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:51:41,383] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:51:41,398] {subprocess.py:85} INFO - Output:
[2022-08-06 21:51:41,399] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:51:41,399] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:51:41,449] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220117T000000, start_date=20220806T215141, end_date=20220806T215141
[2022-08-06 21:51:41,482] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:51:41,570] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:57:04,606] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [queued]>
[2022-08-06 21:57:04,619] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [queued]>
[2022-08-06 21:57:04,619] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:04,619] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:57:04,620] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:04,638] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-17 00:00:00+00:00
[2022-08-06 21:57:04,646] {standard_task_runner.py:52} INFO - Started process 1707 to run task
[2022-08-06 21:57:04,649] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-17T00:00:00+00:00', '--job-id', '519', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp__j04em6', '--error-file', '/tmp/tmp4kjjr994']
[2022-08-06 21:57:04,649] {standard_task_runner.py:80} INFO - Job 519: Subtask thrid_task
[2022-08-06 21:57:04,731] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:57:04,858] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-17T00:00:00+00:00
[2022-08-06 21:57:04,859] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:57:04,860] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:57:04,877] {subprocess.py:85} INFO - Output:
[2022-08-06 21:57:04,880] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:57:04,880] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:57:04,928] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220117T000000, start_date=20220806T215704, end_date=20220806T215704
[2022-08-06 21:57:04,980] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:57:05,027] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:12:05,556] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [queued]>
[2022-08-06 22:12:05,571] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [queued]>
[2022-08-06 22:12:05,572] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:05,572] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:12:05,572] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:05,590] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-17 00:00:00+00:00
[2022-08-06 22:12:05,597] {standard_task_runner.py:52} INFO - Started process 1711 to run task
[2022-08-06 22:12:05,600] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-17T00:00:00+00:00', '--job-id', '518', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpp4k5l3ru', '--error-file', '/tmp/tmpofi17jsh']
[2022-08-06 22:12:05,601] {standard_task_runner.py:80} INFO - Job 518: Subtask thrid_task
[2022-08-06 22:12:05,673] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:12:05,758] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-17T00:00:00+00:00
[2022-08-06 22:12:05,759] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:12:05,760] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:12:05,772] {subprocess.py:85} INFO - Output:
[2022-08-06 22:12:05,773] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:12:05,773] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:12:05,814] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220117T000000, start_date=20220806T221205, end_date=20220806T221205
[2022-08-06 22:12:05,852] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:12:05,883] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:23:25,920] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [queued]>
[2022-08-06 22:23:25,931] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [queued]>
[2022-08-06 22:23:25,931] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:25,931] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:23:25,931] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:25,946] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-17 00:00:00+00:00
[2022-08-06 22:23:25,951] {standard_task_runner.py:52} INFO - Started process 1761 to run task
[2022-08-06 22:23:25,953] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-17T00:00:00+00:00', '--job-id', '521', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp3p2dkk3n', '--error-file', '/tmp/tmp8p35ziyt']
[2022-08-06 22:23:25,953] {standard_task_runner.py:80} INFO - Job 521: Subtask thrid_task
[2022-08-06 22:23:26,007] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-17T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:23:26,077] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-17T00:00:00+00:00
[2022-08-06 22:23:26,078] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:23:26,078] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:23:26,088] {subprocess.py:85} INFO - Output:
[2022-08-06 22:23:26,090] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:23:26,090] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:23:26,116] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220117T000000, start_date=20220806T222325, end_date=20220806T222326
[2022-08-06 22:23:26,164] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:23:26,191] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
