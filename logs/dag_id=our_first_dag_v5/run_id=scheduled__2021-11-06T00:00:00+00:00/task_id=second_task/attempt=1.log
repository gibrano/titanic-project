[2022-08-06 19:37:02,877] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [queued]>
[2022-08-06 19:37:02,900] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [queued]>
[2022-08-06 19:37:02,900] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:02,900] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:37:02,900] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:02,922] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2021-11-06 00:00:00+00:00
[2022-08-06 19:37:02,929] {standard_task_runner.py:52} INFO - Started process 1052 to run task
[2022-08-06 19:37:02,933] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2021-11-06T00:00:00+00:00', '--job-id', '304', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpmpiarsg_', '--error-file', '/tmp/tmp_5n4fekk']
[2022-08-06 19:37:02,933] {standard_task_runner.py:80} INFO - Job 304: Subtask second_task
[2022-08-06 19:37:03,013] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:37:03,110] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2021-11-06T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-11-06T00:00:00+00:00
[2022-08-06 19:37:03,111] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:37:03,112] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 19:37:03,126] {subprocess.py:85} INFO - Output:
[2022-08-06 19:37:03,128] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 19:37:03,128] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:37:03,170] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20211106T000000, start_date=20220806T193702, end_date=20220806T193703
[2022-08-06 19:37:03,225] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:37:03,268] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:50:54,102] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [queued]>
[2022-08-06 21:50:54,118] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [queued]>
[2022-08-06 21:50:54,119] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:50:54,119] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:50:54,119] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:50:54,140] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2021-11-06 00:00:00+00:00
[2022-08-06 21:50:54,147] {standard_task_runner.py:52} INFO - Started process 1220 to run task
[2022-08-06 21:50:54,149] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2021-11-06T00:00:00+00:00', '--job-id', '301', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpyloztstp', '--error-file', '/tmp/tmp78c_5mc0']
[2022-08-06 21:50:54,149] {standard_task_runner.py:80} INFO - Job 301: Subtask second_task
[2022-08-06 21:50:54,216] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:50:54,309] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2021-11-06T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-11-06T00:00:00+00:00
[2022-08-06 21:50:54,310] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:50:54,311] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 21:50:54,325] {subprocess.py:85} INFO - Output:
[2022-08-06 21:50:54,327] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 21:50:54,327] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:50:54,361] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20211106T000000, start_date=20220806T215054, end_date=20220806T215054
[2022-08-06 21:50:54,401] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:50:54,429] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:56:22,526] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [queued]>
[2022-08-06 21:56:22,541] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [queued]>
[2022-08-06 21:56:22,541] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:56:22,541] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:56:22,541] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:56:22,557] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2021-11-06 00:00:00+00:00
[2022-08-06 21:56:22,563] {standard_task_runner.py:52} INFO - Started process 1035 to run task
[2022-08-06 21:56:22,566] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2021-11-06T00:00:00+00:00', '--job-id', '304', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmprmvz0j3c', '--error-file', '/tmp/tmpsfw701cc']
[2022-08-06 21:56:22,566] {standard_task_runner.py:80} INFO - Job 304: Subtask second_task
[2022-08-06 21:56:22,652] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:56:22,762] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2021-11-06T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-11-06T00:00:00+00:00
[2022-08-06 21:56:22,763] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:56:22,764] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 21:56:22,779] {subprocess.py:85} INFO - Output:
[2022-08-06 21:56:22,781] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 21:56:22,781] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:56:22,817] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20211106T000000, start_date=20220806T215622, end_date=20220806T215622
[2022-08-06 21:56:22,857] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:56:22,890] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:11:22,425] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [queued]>
[2022-08-06 22:11:22,439] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [queued]>
[2022-08-06 22:11:22,440] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:11:22,440] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:11:22,440] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:11:22,462] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2021-11-06 00:00:00+00:00
[2022-08-06 22:11:22,469] {standard_task_runner.py:52} INFO - Started process 1030 to run task
[2022-08-06 22:11:22,473] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2021-11-06T00:00:00+00:00', '--job-id', '304', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpuep_u3y0', '--error-file', '/tmp/tmpebaufjbc']
[2022-08-06 22:11:22,473] {standard_task_runner.py:80} INFO - Job 304: Subtask second_task
[2022-08-06 22:11:22,586] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:11:22,686] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2021-11-06T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-11-06T00:00:00+00:00
[2022-08-06 22:11:22,688] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:11:22,688] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 22:11:22,704] {subprocess.py:85} INFO - Output:
[2022-08-06 22:11:22,706] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 22:11:22,706] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:11:22,739] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20211106T000000, start_date=20220806T221122, end_date=20220806T221122
[2022-08-06 22:11:22,764] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:11:22,796] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:19:07,191] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [queued]>
[2022-08-06 22:19:07,211] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [queued]>
[2022-08-06 22:19:07,211] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:19:07,211] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:19:07,212] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:19:07,230] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2021-11-06 00:00:00+00:00
[2022-08-06 22:19:07,237] {standard_task_runner.py:52} INFO - Started process 1051 to run task
[2022-08-06 22:19:07,240] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2021-11-06T00:00:00+00:00', '--job-id', '304', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpbi493kk4', '--error-file', '/tmp/tmpf38pry59']
[2022-08-06 22:19:07,240] {standard_task_runner.py:80} INFO - Job 304: Subtask second_task
[2022-08-06 22:19:07,315] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [running]> on host ed53bde1c44a
[2022-08-06 22:19:07,404] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2021-11-06T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-11-06T00:00:00+00:00
[2022-08-06 22:19:07,405] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:19:07,405] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 22:19:07,423] {subprocess.py:85} INFO - Output:
[2022-08-06 22:19:07,425] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 22:19:07,425] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:19:07,462] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20211106T000000, start_date=20220806T221907, end_date=20220806T221907
[2022-08-06 22:19:07,492] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:19:07,566] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:22:46,724] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [queued]>
[2022-08-06 22:22:46,740] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [queued]>
[2022-08-06 22:22:46,740] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:22:46,740] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:22:46,741] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:22:46,758] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2021-11-06 00:00:00+00:00
[2022-08-06 22:22:46,766] {standard_task_runner.py:52} INFO - Started process 1093 to run task
[2022-08-06 22:22:46,769] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2021-11-06T00:00:00+00:00', '--job-id', '306', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp3n1o67xm', '--error-file', '/tmp/tmp66_ui1ko']
[2022-08-06 22:22:46,769] {standard_task_runner.py:80} INFO - Job 306: Subtask second_task
[2022-08-06 22:22:46,855] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2021-11-06T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:22:46,978] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2021-11-06T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-11-06T00:00:00+00:00
[2022-08-06 22:22:46,980] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:22:46,981] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 22:22:47,004] {subprocess.py:85} INFO - Output:
[2022-08-06 22:22:47,006] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 22:22:47,007] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:22:47,066] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20211106T000000, start_date=20220806T222246, end_date=20220806T222247
[2022-08-06 22:22:47,101] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:22:47,150] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
