[2022-08-06 19:37:41,804] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [queued]>
[2022-08-06 19:37:41,822] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [queued]>
[2022-08-06 19:37:41,822] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:41,822] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:37:41,823] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:41,845] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-01-06 00:00:00+00:00
[2022-08-06 19:37:41,852] {standard_task_runner.py:52} INFO - Started process 1629 to run task
[2022-08-06 19:37:41,855] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-01-06T00:00:00+00:00', '--job-id', '491', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp19fiazgq', '--error-file', '/tmp/tmpmprna1mf']
[2022-08-06 19:37:41,856] {standard_task_runner.py:80} INFO - Job 491: Subtask second_task
[2022-08-06 19:37:41,946] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:37:42,053] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-06T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-06T00:00:00+00:00
[2022-08-06 19:37:42,054] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:37:42,055] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 19:37:42,071] {subprocess.py:85} INFO - Output:
[2022-08-06 19:37:42,073] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 19:37:42,073] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:37:42,111] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220106T000000, start_date=20220806T193741, end_date=20220806T193742
[2022-08-06 19:37:42,147] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:37:42,200] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:51:32,787] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [queued]>
[2022-08-06 21:51:32,798] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [queued]>
[2022-08-06 21:51:32,798] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:32,798] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:51:32,798] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:32,813] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-01-06 00:00:00+00:00
[2022-08-06 21:51:32,819] {standard_task_runner.py:52} INFO - Started process 1798 to run task
[2022-08-06 21:51:32,821] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-01-06T00:00:00+00:00', '--job-id', '485', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp_nkjh1v1', '--error-file', '/tmp/tmpyrhq65d3']
[2022-08-06 21:51:32,822] {standard_task_runner.py:80} INFO - Job 485: Subtask second_task
[2022-08-06 21:51:32,879] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:51:32,955] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-06T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-06T00:00:00+00:00
[2022-08-06 21:51:32,956] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:51:32,956] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 21:51:32,969] {subprocess.py:85} INFO - Output:
[2022-08-06 21:51:32,970] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 21:51:32,970] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:51:32,995] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220106T000000, start_date=20220806T215132, end_date=20220806T215132
[2022-08-06 21:51:33,033] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:51:33,063] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:56:57,462] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [queued]>
[2022-08-06 21:56:57,474] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [queued]>
[2022-08-06 21:56:57,475] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:56:57,475] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:56:57,475] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:56:57,492] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-01-06 00:00:00+00:00
[2022-08-06 21:56:57,497] {standard_task_runner.py:52} INFO - Started process 1607 to run task
[2022-08-06 21:56:57,500] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-01-06T00:00:00+00:00', '--job-id', '488', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpixlhtxmx', '--error-file', '/tmp/tmp98ims7oc']
[2022-08-06 21:56:57,500] {standard_task_runner.py:80} INFO - Job 488: Subtask second_task
[2022-08-06 21:56:57,558] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:56:57,647] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-06T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-06T00:00:00+00:00
[2022-08-06 21:56:57,648] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:56:57,648] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 21:56:57,660] {subprocess.py:85} INFO - Output:
[2022-08-06 21:56:57,661] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 21:56:57,662] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:56:57,686] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220106T000000, start_date=20220806T215657, end_date=20220806T215657
[2022-08-06 21:56:57,711] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:56:57,740] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:12:01,015] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [queued]>
[2022-08-06 22:12:01,028] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [queued]>
[2022-08-06 22:12:01,029] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:01,029] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:12:01,029] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:01,043] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-01-06 00:00:00+00:00
[2022-08-06 22:12:01,050] {standard_task_runner.py:52} INFO - Started process 1613 to run task
[2022-08-06 22:12:01,053] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-01-06T00:00:00+00:00', '--job-id', '488', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpsbtebvb7', '--error-file', '/tmp/tmpbdb8g5cp']
[2022-08-06 22:12:01,053] {standard_task_runner.py:80} INFO - Job 488: Subtask second_task
[2022-08-06 22:12:01,137] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:12:01,255] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-06T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-06T00:00:00+00:00
[2022-08-06 22:12:01,257] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:12:01,257] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 22:12:01,275] {subprocess.py:85} INFO - Output:
[2022-08-06 22:12:01,278] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 22:12:01,279] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:12:01,325] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220106T000000, start_date=20220806T221201, end_date=20220806T221201
[2022-08-06 22:12:01,385] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:12:01,425] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:23:21,322] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [queued]>
[2022-08-06 22:23:21,336] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [queued]>
[2022-08-06 22:23:21,336] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:21,336] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:23:21,336] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:21,354] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-01-06 00:00:00+00:00
[2022-08-06 22:23:21,362] {standard_task_runner.py:52} INFO - Started process 1669 to run task
[2022-08-06 22:23:21,365] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-01-06T00:00:00+00:00', '--job-id', '489', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp81su8gtl', '--error-file', '/tmp/tmpcsdfbzmx']
[2022-08-06 22:23:21,365] {standard_task_runner.py:80} INFO - Job 489: Subtask second_task
[2022-08-06 22:23:21,439] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-06T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:23:21,535] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-06T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-06T00:00:00+00:00
[2022-08-06 22:23:21,535] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:23:21,536] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 22:23:21,550] {subprocess.py:85} INFO - Output:
[2022-08-06 22:23:21,552] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 22:23:21,552] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:23:21,588] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220106T000000, start_date=20220806T222321, end_date=20220806T222321
[2022-08-06 22:23:21,617] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:23:21,666] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
