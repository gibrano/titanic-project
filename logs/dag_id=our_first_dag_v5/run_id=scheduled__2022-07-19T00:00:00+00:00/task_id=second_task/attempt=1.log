[2022-08-06 19:39:39,370] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [queued]>
[2022-08-06 19:39:39,391] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [queued]>
[2022-08-06 19:39:39,391] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:39:39,391] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:39:39,391] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:39:39,423] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-07-19 00:00:00+00:00
[2022-08-06 19:39:39,431] {standard_task_runner.py:52} INFO - Started process 3466 to run task
[2022-08-06 19:39:39,434] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-07-19T00:00:00+00:00', '--job-id', '1070', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpg6c918pi', '--error-file', '/tmp/tmp6is9ydcm']
[2022-08-06 19:39:39,435] {standard_task_runner.py:80} INFO - Job 1070: Subtask second_task
[2022-08-06 19:39:39,585] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:39:39,752] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-19T00:00:00+00:00
[2022-08-06 19:39:39,753] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:39:39,756] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 19:39:39,778] {subprocess.py:85} INFO - Output:
[2022-08-06 19:39:39,782] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 19:39:39,782] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:39:39,888] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220719T000000, start_date=20220806T193939, end_date=20220806T193939
[2022-08-06 19:39:39,933] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:39:39,989] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:53:31,684] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [queued]>
[2022-08-06 21:53:31,696] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [queued]>
[2022-08-06 21:53:31,696] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:53:31,696] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:53:31,696] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:53:31,713] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-07-19 00:00:00+00:00
[2022-08-06 21:53:31,719] {standard_task_runner.py:52} INFO - Started process 3636 to run task
[2022-08-06 21:53:31,721] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-07-19T00:00:00+00:00', '--job-id', '1067', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpnu0an2oy', '--error-file', '/tmp/tmpz568iqii']
[2022-08-06 21:53:31,721] {standard_task_runner.py:80} INFO - Job 1067: Subtask second_task
[2022-08-06 21:53:31,799] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:53:31,923] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-19T00:00:00+00:00
[2022-08-06 21:53:31,924] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:53:31,925] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 21:53:31,941] {subprocess.py:85} INFO - Output:
[2022-08-06 21:53:31,943] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 21:53:31,943] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:53:32,020] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220719T000000, start_date=20220806T215331, end_date=20220806T215332
[2022-08-06 21:53:32,053] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:53:32,101] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:58:53,559] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [queued]>
[2022-08-06 21:58:53,574] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [queued]>
[2022-08-06 21:58:53,574] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:58:53,574] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:58:53,574] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:58:53,592] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-07-19 00:00:00+00:00
[2022-08-06 21:58:53,599] {standard_task_runner.py:52} INFO - Started process 3436 to run task
[2022-08-06 21:58:53,602] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-07-19T00:00:00+00:00', '--job-id', '1068', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpq00sfp61', '--error-file', '/tmp/tmpjfyj4lof']
[2022-08-06 21:58:53,602] {standard_task_runner.py:80} INFO - Job 1068: Subtask second_task
[2022-08-06 21:58:53,676] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:58:53,762] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-19T00:00:00+00:00
[2022-08-06 21:58:53,763] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:58:53,763] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 21:58:53,778] {subprocess.py:85} INFO - Output:
[2022-08-06 21:58:53,780] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 21:58:53,780] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:58:53,811] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220719T000000, start_date=20220806T215853, end_date=20220806T215853
[2022-08-06 21:58:53,854] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:58:53,887] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:13:54,661] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [queued]>
[2022-08-06 22:13:54,675] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [queued]>
[2022-08-06 22:13:54,676] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:13:54,676] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:13:54,676] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:13:54,691] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-07-19 00:00:00+00:00
[2022-08-06 22:13:54,697] {standard_task_runner.py:52} INFO - Started process 3446 to run task
[2022-08-06 22:13:54,699] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-07-19T00:00:00+00:00', '--job-id', '1069', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp34p72uch', '--error-file', '/tmp/tmpj3wdnvgg']
[2022-08-06 22:13:54,700] {standard_task_runner.py:80} INFO - Job 1069: Subtask second_task
[2022-08-06 22:13:54,785] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:13:54,907] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-19T00:00:00+00:00
[2022-08-06 22:13:54,907] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:13:54,908] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 22:13:54,925] {subprocess.py:85} INFO - Output:
[2022-08-06 22:13:54,927] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 22:13:54,927] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:13:54,971] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220719T000000, start_date=20220806T221354, end_date=20220806T221354
[2022-08-06 22:13:55,031] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:13:55,069] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:25:09,913] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [queued]>
[2022-08-06 22:25:09,930] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [queued]>
[2022-08-06 22:25:09,930] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:25:09,930] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:25:09,931] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:25:09,951] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-07-19 00:00:00+00:00
[2022-08-06 22:25:09,958] {standard_task_runner.py:52} INFO - Started process 3500 to run task
[2022-08-06 22:25:09,961] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-07-19T00:00:00+00:00', '--job-id', '1072', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpo_gsmwzw', '--error-file', '/tmp/tmpbqru65gi']
[2022-08-06 22:25:09,961] {standard_task_runner.py:80} INFO - Job 1072: Subtask second_task
[2022-08-06 22:25:10,034] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-07-19T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:25:10,123] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-07-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-07-19T00:00:00+00:00
[2022-08-06 22:25:10,124] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:25:10,124] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 22:25:10,138] {subprocess.py:85} INFO - Output:
[2022-08-06 22:25:10,140] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 22:25:10,140] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:25:10,172] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220719T000000, start_date=20220806T222509, end_date=20220806T222510
[2022-08-06 22:25:10,212] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:25:10,244] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
