[2022-08-06 19:37:45,491] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [queued]>
[2022-08-06 19:37:45,506] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [queued]>
[2022-08-06 19:37:45,506] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:45,507] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:37:45,507] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:45,527] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-13 00:00:00+00:00
[2022-08-06 19:37:45,534] {standard_task_runner.py:52} INFO - Started process 1681 to run task
[2022-08-06 19:37:45,537] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-13T00:00:00+00:00', '--job-id', '506', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp34on5pg5', '--error-file', '/tmp/tmpvezlqt73']
[2022-08-06 19:37:45,537] {standard_task_runner.py:80} INFO - Job 506: Subtask thrid_task
[2022-08-06 19:37:45,630] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:37:45,797] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-13T00:00:00+00:00
[2022-08-06 19:37:45,799] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:37:45,799] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 19:37:45,815] {subprocess.py:85} INFO - Output:
[2022-08-06 19:37:45,817] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 19:37:45,818] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:37:45,856] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220113T000000, start_date=20220806T193745, end_date=20220806T193745
[2022-08-06 19:37:45,911] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:37:45,948] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:51:36,892] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [queued]>
[2022-08-06 21:51:36,907] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [queued]>
[2022-08-06 21:51:36,907] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:36,907] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:51:36,907] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:36,924] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-13 00:00:00+00:00
[2022-08-06 21:51:36,931] {standard_task_runner.py:52} INFO - Started process 1864 to run task
[2022-08-06 21:51:36,934] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-13T00:00:00+00:00', '--job-id', '506', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp1lafhvi3', '--error-file', '/tmp/tmp1fpt7n47']
[2022-08-06 21:51:36,935] {standard_task_runner.py:80} INFO - Job 506: Subtask thrid_task
[2022-08-06 21:51:37,010] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:51:37,097] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-13T00:00:00+00:00
[2022-08-06 21:51:37,098] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:51:37,099] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:51:37,115] {subprocess.py:85} INFO - Output:
[2022-08-06 21:51:37,117] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:51:37,117] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:51:37,153] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220113T000000, start_date=20220806T215136, end_date=20220806T215137
[2022-08-06 21:51:37,186] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:51:37,216] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:57:01,109] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [queued]>
[2022-08-06 21:57:01,126] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [queued]>
[2022-08-06 21:57:01,126] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:01,126] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:57:01,126] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:01,146] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-13 00:00:00+00:00
[2022-08-06 21:57:01,153] {standard_task_runner.py:52} INFO - Started process 1669 to run task
[2022-08-06 21:57:01,156] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-13T00:00:00+00:00', '--job-id', '507', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp1bp8psb_', '--error-file', '/tmp/tmpvxziki9q']
[2022-08-06 21:57:01,156] {standard_task_runner.py:80} INFO - Job 507: Subtask thrid_task
[2022-08-06 21:57:01,233] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:57:01,329] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-13T00:00:00+00:00
[2022-08-06 21:57:01,330] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:57:01,331] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:57:01,346] {subprocess.py:85} INFO - Output:
[2022-08-06 21:57:01,348] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:57:01,348] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:57:01,389] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220113T000000, start_date=20220806T215701, end_date=20220806T215701
[2022-08-06 21:57:01,447] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:57:01,482] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:12:04,570] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [queued]>
[2022-08-06 22:12:04,585] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [queued]>
[2022-08-06 22:12:04,585] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:04,585] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:12:04,585] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:04,604] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-13 00:00:00+00:00
[2022-08-06 22:12:04,611] {standard_task_runner.py:52} INFO - Started process 1677 to run task
[2022-08-06 22:12:04,614] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-13T00:00:00+00:00', '--job-id', '508', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp5j6hfzmk', '--error-file', '/tmp/tmpxe24n0fa']
[2022-08-06 22:12:04,615] {standard_task_runner.py:80} INFO - Job 508: Subtask thrid_task
[2022-08-06 22:12:04,704] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:12:04,806] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-13T00:00:00+00:00
[2022-08-06 22:12:04,806] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:12:04,807] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:12:04,822] {subprocess.py:85} INFO - Output:
[2022-08-06 22:12:04,824] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:12:04,824] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:12:04,879] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220113T000000, start_date=20220806T221204, end_date=20220806T221204
[2022-08-06 22:12:04,908] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:12:04,966] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:23:24,940] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [queued]>
[2022-08-06 22:23:24,959] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [queued]>
[2022-08-06 22:23:24,959] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:24,959] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:23:24,959] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:24,985] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-13 00:00:00+00:00
[2022-08-06 22:23:24,994] {standard_task_runner.py:52} INFO - Started process 1736 to run task
[2022-08-06 22:23:25,002] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-13T00:00:00+00:00', '--job-id', '512', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpbk_90ej3', '--error-file', '/tmp/tmptikjj9wj']
[2022-08-06 22:23:25,002] {standard_task_runner.py:80} INFO - Job 512: Subtask thrid_task
[2022-08-06 22:23:25,083] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-13T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:23:25,193] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-13T00:00:00+00:00
[2022-08-06 22:23:25,194] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:23:25,195] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:23:25,211] {subprocess.py:85} INFO - Output:
[2022-08-06 22:23:25,213] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:23:25,214] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:23:25,258] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220113T000000, start_date=20220806T222324, end_date=20220806T222325
[2022-08-06 22:23:25,293] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:23:25,344] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
