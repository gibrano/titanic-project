[2022-08-06 19:37:45,526] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [queued]>
[2022-08-06 19:37:45,546] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [queued]>
[2022-08-06 19:37:45,546] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:45,546] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:37:45,546] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:45,568] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-01-12 00:00:00+00:00
[2022-08-06 19:37:45,575] {standard_task_runner.py:52} INFO - Started process 1684 to run task
[2022-08-06 19:37:45,577] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-01-12T00:00:00+00:00', '--job-id', '507', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp8s121h4f', '--error-file', '/tmp/tmpfkbdk0wt']
[2022-08-06 19:37:45,578] {standard_task_runner.py:80} INFO - Job 507: Subtask second_task
[2022-08-06 19:37:45,733] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:37:45,855] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-12T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-12T00:00:00+00:00
[2022-08-06 19:37:45,856] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:37:45,857] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 19:37:45,870] {subprocess.py:85} INFO - Output:
[2022-08-06 19:37:45,871] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 19:37:45,872] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:37:45,930] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220112T000000, start_date=20220806T193745, end_date=20220806T193745
[2022-08-06 19:37:45,993] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:37:46,049] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:51:36,738] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [queued]>
[2022-08-06 21:51:36,754] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [queued]>
[2022-08-06 21:51:36,754] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:36,754] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:51:36,754] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:36,771] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-01-12 00:00:00+00:00
[2022-08-06 21:51:36,777] {standard_task_runner.py:52} INFO - Started process 1860 to run task
[2022-08-06 21:51:36,780] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-01-12T00:00:00+00:00', '--job-id', '505', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpx_8k4q0t', '--error-file', '/tmp/tmpb97xg8e3']
[2022-08-06 21:51:36,780] {standard_task_runner.py:80} INFO - Job 505: Subtask second_task
[2022-08-06 21:51:36,852] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:51:36,953] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-12T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-12T00:00:00+00:00
[2022-08-06 21:51:36,954] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:51:36,954] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 21:51:36,969] {subprocess.py:85} INFO - Output:
[2022-08-06 21:51:36,971] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 21:51:36,971] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:51:37,026] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220112T000000, start_date=20220806T215136, end_date=20220806T215137
[2022-08-06 21:51:37,071] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:51:37,109] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:57:00,922] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [queued]>
[2022-08-06 21:57:00,941] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [queued]>
[2022-08-06 21:57:00,941] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:00,941] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:57:00,941] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:00,960] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-01-12 00:00:00+00:00
[2022-08-06 21:57:00,968] {standard_task_runner.py:52} INFO - Started process 1664 to run task
[2022-08-06 21:57:00,971] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-01-12T00:00:00+00:00', '--job-id', '506', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpn4_lp4t6', '--error-file', '/tmp/tmp1ip_0fzg']
[2022-08-06 21:57:00,971] {standard_task_runner.py:80} INFO - Job 506: Subtask second_task
[2022-08-06 21:57:01,042] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:57:01,133] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-12T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-12T00:00:00+00:00
[2022-08-06 21:57:01,134] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:57:01,134] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 21:57:01,151] {subprocess.py:85} INFO - Output:
[2022-08-06 21:57:01,153] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 21:57:01,153] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:57:01,191] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220112T000000, start_date=20220806T215700, end_date=20220806T215701
[2022-08-06 21:57:01,222] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:57:01,263] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:12:04,526] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [queued]>
[2022-08-06 22:12:04,542] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [queued]>
[2022-08-06 22:12:04,543] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:04,543] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:12:04,543] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:04,558] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-01-12 00:00:00+00:00
[2022-08-06 22:12:04,565] {standard_task_runner.py:52} INFO - Started process 1675 to run task
[2022-08-06 22:12:04,567] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-01-12T00:00:00+00:00', '--job-id', '507', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpj1coekrs', '--error-file', '/tmp/tmpqqsa7tmt']
[2022-08-06 22:12:04,568] {standard_task_runner.py:80} INFO - Job 507: Subtask second_task
[2022-08-06 22:12:04,645] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:12:04,757] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-12T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-12T00:00:00+00:00
[2022-08-06 22:12:04,759] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:12:04,759] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 22:12:04,772] {subprocess.py:85} INFO - Output:
[2022-08-06 22:12:04,774] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 22:12:04,774] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:12:04,867] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220112T000000, start_date=20220806T221204, end_date=20220806T221204
[2022-08-06 22:12:04,900] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:12:04,953] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:23:24,469] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [queued]>
[2022-08-06 22:23:24,484] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [queued]>
[2022-08-06 22:23:24,484] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:24,484] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:23:24,484] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:24,501] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-01-12 00:00:00+00:00
[2022-08-06 22:23:24,508] {standard_task_runner.py:52} INFO - Started process 1718 to run task
[2022-08-06 22:23:24,511] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-01-12T00:00:00+00:00', '--job-id', '506', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpydjayloh', '--error-file', '/tmp/tmpnjr6yz8g']
[2022-08-06 22:23:24,511] {standard_task_runner.py:80} INFO - Job 506: Subtask second_task
[2022-08-06 22:23:24,606] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-01-12T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:23:24,736] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-12T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-12T00:00:00+00:00
[2022-08-06 22:23:24,737] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:23:24,738] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 22:23:24,753] {subprocess.py:85} INFO - Output:
[2022-08-06 22:23:24,755] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 22:23:24,756] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:23:24,868] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220112T000000, start_date=20220806T222324, end_date=20220806T222324
[2022-08-06 22:23:24,923] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:23:24,976] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
