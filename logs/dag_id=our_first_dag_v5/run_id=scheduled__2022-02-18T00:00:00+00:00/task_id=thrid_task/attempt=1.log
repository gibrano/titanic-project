[2022-08-06 19:38:06,012] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [queued]>
[2022-08-06 19:38:06,027] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [queued]>
[2022-08-06 19:38:06,027] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:38:06,027] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:38:06,027] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:38:06,049] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-02-18 00:00:00+00:00
[2022-08-06 19:38:06,057] {standard_task_runner.py:52} INFO - Started process 2023 to run task
[2022-08-06 19:38:06,060] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-02-18T00:00:00+00:00', '--job-id', '614', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp098vbbc5', '--error-file', '/tmp/tmp81zpmswh']
[2022-08-06 19:38:06,060] {standard_task_runner.py:80} INFO - Job 614: Subtask thrid_task
[2022-08-06 19:38:06,143] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:38:06,289] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-18T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-18T00:00:00+00:00
[2022-08-06 19:38:06,290] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:38:06,291] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 19:38:06,309] {subprocess.py:85} INFO - Output:
[2022-08-06 19:38:06,312] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 19:38:06,312] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:38:06,349] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220218T000000, start_date=20220806T193806, end_date=20220806T193806
[2022-08-06 19:38:06,394] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:38:06,440] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:51:59,377] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [queued]>
[2022-08-06 21:51:59,390] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [queued]>
[2022-08-06 21:51:59,390] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:59,390] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:51:59,390] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:59,407] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-02-18 00:00:00+00:00
[2022-08-06 21:51:59,415] {standard_task_runner.py:52} INFO - Started process 2217 to run task
[2022-08-06 21:51:59,418] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-02-18T00:00:00+00:00', '--job-id', '616', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp_e50zqha', '--error-file', '/tmp/tmpqxmg_4xc']
[2022-08-06 21:51:59,418] {standard_task_runner.py:80} INFO - Job 616: Subtask thrid_task
[2022-08-06 21:51:59,514] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:51:59,635] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-18T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-18T00:00:00+00:00
[2022-08-06 21:51:59,636] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:51:59,637] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:51:59,654] {subprocess.py:85} INFO - Output:
[2022-08-06 21:51:59,656] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:51:59,656] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:51:59,686] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220218T000000, start_date=20220806T215159, end_date=20220806T215159
[2022-08-06 21:51:59,712] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:51:59,753] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:57:23,629] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [queued]>
[2022-08-06 21:57:23,645] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [queued]>
[2022-08-06 21:57:23,645] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:23,645] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:57:23,646] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:23,665] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-02-18 00:00:00+00:00
[2022-08-06 21:57:23,673] {standard_task_runner.py:52} INFO - Started process 2009 to run task
[2022-08-06 21:57:23,676] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-02-18T00:00:00+00:00', '--job-id', '616', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmprx30_dvn', '--error-file', '/tmp/tmpi3x9ka5v']
[2022-08-06 21:57:23,677] {standard_task_runner.py:80} INFO - Job 616: Subtask thrid_task
[2022-08-06 21:57:23,756] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:57:23,890] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-18T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-18T00:00:00+00:00
[2022-08-06 21:57:23,891] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:57:23,892] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:57:23,909] {subprocess.py:85} INFO - Output:
[2022-08-06 21:57:23,911] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:57:23,912] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:57:23,954] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220218T000000, start_date=20220806T215723, end_date=20220806T215723
[2022-08-06 21:57:24,008] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:57:24,047] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:12:24,321] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [queued]>
[2022-08-06 22:12:24,331] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [queued]>
[2022-08-06 22:12:24,331] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:24,331] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:12:24,331] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:24,346] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-02-18 00:00:00+00:00
[2022-08-06 22:12:24,352] {standard_task_runner.py:52} INFO - Started process 2016 to run task
[2022-08-06 22:12:24,355] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-02-18T00:00:00+00:00', '--job-id', '615', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp4lgsw2ja', '--error-file', '/tmp/tmpowa2xsz_']
[2022-08-06 22:12:24,355] {standard_task_runner.py:80} INFO - Job 615: Subtask thrid_task
[2022-08-06 22:12:24,425] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:12:24,511] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-18T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-18T00:00:00+00:00
[2022-08-06 22:12:24,512] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:12:24,513] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:12:24,524] {subprocess.py:85} INFO - Output:
[2022-08-06 22:12:24,526] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:12:24,526] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:12:24,552] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220218T000000, start_date=20220806T221224, end_date=20220806T221224
[2022-08-06 22:12:24,606] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:12:24,635] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:23:48,238] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [queued]>
[2022-08-06 22:23:48,257] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [queued]>
[2022-08-06 22:23:48,257] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:48,257] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:23:48,258] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:48,279] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-02-18 00:00:00+00:00
[2022-08-06 22:23:48,288] {standard_task_runner.py:52} INFO - Started process 2082 to run task
[2022-08-06 22:23:48,291] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-02-18T00:00:00+00:00', '--job-id', '623', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpripq7v9t', '--error-file', '/tmp/tmp1lynz7oh']
[2022-08-06 22:23:48,291] {standard_task_runner.py:80} INFO - Job 623: Subtask thrid_task
[2022-08-06 22:23:48,385] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-02-18T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:23:48,503] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-18T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-18T00:00:00+00:00
[2022-08-06 22:23:48,504] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:23:48,505] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:23:48,519] {subprocess.py:85} INFO - Output:
[2022-08-06 22:23:48,520] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:23:48,520] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:23:48,558] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220218T000000, start_date=20220806T222348, end_date=20220806T222348
[2022-08-06 22:23:48,583] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:23:48,641] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
