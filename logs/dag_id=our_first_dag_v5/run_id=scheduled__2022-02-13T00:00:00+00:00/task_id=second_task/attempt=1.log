[2022-08-06 19:38:04,960] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [queued]>
[2022-08-06 19:38:04,977] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [queued]>
[2022-08-06 19:38:04,977] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:38:04,977] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:38:04,977] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:38:04,998] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-02-13 00:00:00+00:00
[2022-08-06 19:38:05,005] {standard_task_runner.py:52} INFO - Started process 1989 to run task
[2022-08-06 19:38:05,007] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-02-13T00:00:00+00:00', '--job-id', '605', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpo3g127v6', '--error-file', '/tmp/tmpvphv_rzx']
[2022-08-06 19:38:05,008] {standard_task_runner.py:80} INFO - Job 605: Subtask second_task
[2022-08-06 19:38:05,105] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:38:05,217] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-13T00:00:00+00:00
[2022-08-06 19:38:05,218] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:38:05,219] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 19:38:05,235] {subprocess.py:85} INFO - Output:
[2022-08-06 19:38:05,237] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 19:38:05,238] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:38:05,292] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220213T000000, start_date=20220806T193804, end_date=20220806T193805
[2022-08-06 19:38:05,344] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:38:05,410] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:51:55,567] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [queued]>
[2022-08-06 21:51:55,583] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [queued]>
[2022-08-06 21:51:55,583] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:55,583] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:51:55,583] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:55,604] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-02-13 00:00:00+00:00
[2022-08-06 21:51:55,611] {standard_task_runner.py:52} INFO - Started process 2168 to run task
[2022-08-06 21:51:55,615] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-02-13T00:00:00+00:00', '--job-id', '602', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpp7o9oe66', '--error-file', '/tmp/tmpaqo07h_0']
[2022-08-06 21:51:55,615] {standard_task_runner.py:80} INFO - Job 602: Subtask second_task
[2022-08-06 21:51:55,698] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:51:55,851] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-13T00:00:00+00:00
[2022-08-06 21:51:55,852] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:51:55,853] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 21:51:55,870] {subprocess.py:85} INFO - Output:
[2022-08-06 21:51:55,871] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 21:51:55,872] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:51:55,903] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220213T000000, start_date=20220806T215155, end_date=20220806T215155
[2022-08-06 21:51:55,946] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:51:55,983] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:57:19,900] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [queued]>
[2022-08-06 21:57:19,915] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [queued]>
[2022-08-06 21:57:19,915] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:19,915] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:57:19,915] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:19,940] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-02-13 00:00:00+00:00
[2022-08-06 21:57:19,948] {standard_task_runner.py:52} INFO - Started process 1967 to run task
[2022-08-06 21:57:19,952] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-02-13T00:00:00+00:00', '--job-id', '600', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp0wqu49s7', '--error-file', '/tmp/tmpi38k9uhu']
[2022-08-06 21:57:19,953] {standard_task_runner.py:80} INFO - Job 600: Subtask second_task
[2022-08-06 21:57:20,032] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:57:20,130] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-13T00:00:00+00:00
[2022-08-06 21:57:20,131] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:57:20,132] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 21:57:20,147] {subprocess.py:85} INFO - Output:
[2022-08-06 21:57:20,149] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 21:57:20,150] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:57:20,189] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220213T000000, start_date=20220806T215719, end_date=20220806T215720
[2022-08-06 21:57:20,244] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:57:20,285] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:12:23,091] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [queued]>
[2022-08-06 22:12:23,105] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [queued]>
[2022-08-06 22:12:23,105] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:23,105] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:12:23,105] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:23,119] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-02-13 00:00:00+00:00
[2022-08-06 22:12:23,137] {standard_task_runner.py:52} INFO - Started process 1970 to run task
[2022-08-06 22:12:23,141] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-02-13T00:00:00+00:00', '--job-id', '601', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpudojmhfk', '--error-file', '/tmp/tmpi0idzkb1']
[2022-08-06 22:12:23,141] {standard_task_runner.py:80} INFO - Job 601: Subtask second_task
[2022-08-06 22:12:23,238] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:12:23,349] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-13T00:00:00+00:00
[2022-08-06 22:12:23,349] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:12:23,350] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 22:12:23,368] {subprocess.py:85} INFO - Output:
[2022-08-06 22:12:23,371] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 22:12:23,371] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:12:23,407] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220213T000000, start_date=20220806T221223, end_date=20220806T221223
[2022-08-06 22:12:23,433] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:12:23,496] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:23:43,348] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [queued]>
[2022-08-06 22:23:43,365] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [queued]>
[2022-08-06 22:23:43,365] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:43,365] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:23:43,365] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:43,383] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-02-13 00:00:00+00:00
[2022-08-06 22:23:43,391] {standard_task_runner.py:52} INFO - Started process 2032 to run task
[2022-08-06 22:23:43,394] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-02-13T00:00:00+00:00', '--job-id', '604', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpcj37i3ap', '--error-file', '/tmp/tmpnren1qu8']
[2022-08-06 22:23:43,395] {standard_task_runner.py:80} INFO - Job 604: Subtask second_task
[2022-08-06 22:23:43,465] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-13T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:23:43,553] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-13T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-13T00:00:00+00:00
[2022-08-06 22:23:43,554] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:23:43,555] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 22:23:43,571] {subprocess.py:85} INFO - Output:
[2022-08-06 22:23:43,573] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 22:23:43,573] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:23:43,611] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220213T000000, start_date=20220806T222343, end_date=20220806T222343
[2022-08-06 22:23:43,645] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:23:43,696] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
