[2022-08-06 19:37:58,031] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [queued]>
[2022-08-06 19:37:58,043] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [queued]>
[2022-08-06 19:37:58,043] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:58,043] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:37:58,043] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:58,060] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-02-04 00:00:00+00:00
[2022-08-06 19:37:58,067] {standard_task_runner.py:52} INFO - Started process 1885 to run task
[2022-08-06 19:37:58,069] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-02-04T00:00:00+00:00', '--job-id', '571', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp0rgu8ser', '--error-file', '/tmp/tmpyw5bjyxz']
[2022-08-06 19:37:58,070] {standard_task_runner.py:80} INFO - Job 571: Subtask second_task
[2022-08-06 19:37:58,135] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:37:58,240] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-04T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-04T00:00:00+00:00
[2022-08-06 19:37:58,241] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:37:58,241] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 19:37:58,254] {subprocess.py:85} INFO - Output:
[2022-08-06 19:37:58,255] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 19:37:58,256] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:37:58,292] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220204T000000, start_date=20220806T193758, end_date=20220806T193758
[2022-08-06 19:37:58,321] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:37:58,353] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:51:51,388] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [queued]>
[2022-08-06 21:51:51,406] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [queued]>
[2022-08-06 21:51:51,406] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:51,406] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:51:51,406] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:51,423] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-02-04 00:00:00+00:00
[2022-08-06 21:51:51,430] {standard_task_runner.py:52} INFO - Started process 2083 to run task
[2022-08-06 21:51:51,433] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-02-04T00:00:00+00:00', '--job-id', '573', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpttvoypu0', '--error-file', '/tmp/tmp0rere2vu']
[2022-08-06 21:51:51,434] {standard_task_runner.py:80} INFO - Job 573: Subtask second_task
[2022-08-06 21:51:51,536] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:51:51,661] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-04T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-04T00:00:00+00:00
[2022-08-06 21:51:51,662] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:51:51,663] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 21:51:51,679] {subprocess.py:85} INFO - Output:
[2022-08-06 21:51:51,681] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 21:51:51,681] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:51:51,726] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220204T000000, start_date=20220806T215151, end_date=20220806T215151
[2022-08-06 21:51:51,769] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:51:51,821] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:57:14,815] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [queued]>
[2022-08-06 21:57:14,829] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [queued]>
[2022-08-06 21:57:14,829] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:14,829] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:57:14,830] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:14,848] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-02-04 00:00:00+00:00
[2022-08-06 21:57:14,855] {standard_task_runner.py:52} INFO - Started process 1880 to run task
[2022-08-06 21:57:14,858] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-02-04T00:00:00+00:00', '--job-id', '575', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpwx2r7rkz', '--error-file', '/tmp/tmpv8p02onm']
[2022-08-06 21:57:14,858] {standard_task_runner.py:80} INFO - Job 575: Subtask second_task
[2022-08-06 21:57:14,925] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:57:15,015] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-04T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-04T00:00:00+00:00
[2022-08-06 21:57:15,016] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:57:15,016] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 21:57:15,032] {subprocess.py:85} INFO - Output:
[2022-08-06 21:57:15,034] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 21:57:15,034] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:57:15,066] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220204T000000, start_date=20220806T215714, end_date=20220806T215715
[2022-08-06 21:57:15,109] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:57:15,168] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:12:18,606] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [queued]>
[2022-08-06 22:12:18,629] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [queued]>
[2022-08-06 22:12:18,630] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:18,630] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:12:18,630] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:18,654] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-02-04 00:00:00+00:00
[2022-08-06 22:12:18,663] {standard_task_runner.py:52} INFO - Started process 1895 to run task
[2022-08-06 22:12:18,667] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-02-04T00:00:00+00:00', '--job-id', '576', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp4kmqdj6k', '--error-file', '/tmp/tmpukg94pa7']
[2022-08-06 22:12:18,667] {standard_task_runner.py:80} INFO - Job 576: Subtask second_task
[2022-08-06 22:12:18,744] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:12:18,841] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-04T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-04T00:00:00+00:00
[2022-08-06 22:12:18,842] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:12:18,842] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 22:12:18,855] {subprocess.py:85} INFO - Output:
[2022-08-06 22:12:18,857] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 22:12:18,857] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:12:18,897] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220204T000000, start_date=20220806T221218, end_date=20220806T221218
[2022-08-06 22:12:18,961] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:12:19,005] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:23:38,536] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [queued]>
[2022-08-06 22:23:38,554] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [queued]>
[2022-08-06 22:23:38,555] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:38,555] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:23:38,555] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:38,570] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): second_task> on 2022-02-04 00:00:00+00:00
[2022-08-06 22:23:38,577] {standard_task_runner.py:52} INFO - Started process 1939 to run task
[2022-08-06 22:23:38,580] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'second_task', 'scheduled__2022-02-04T00:00:00+00:00', '--job-id', '577', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpdkrkyyp7', '--error-file', '/tmp/tmpcan89aj3']
[2022-08-06 22:23:38,581] {standard_task_runner.py:80} INFO - Job 577: Subtask second_task
[2022-08-06 22:23:38,670] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.second_task scheduled__2022-02-04T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:23:38,767] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=second_task
AIRFLOW_CTX_EXECUTION_DATE=2022-02-04T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-02-04T00:00:00+00:00
[2022-08-06 22:23:38,769] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:23:38,769] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task2 and will be running after task1!']
[2022-08-06 22:23:38,781] {subprocess.py:85} INFO - Output:
[2022-08-06 22:23:38,782] {subprocess.py:92} INFO - hey, I am task2 and will be running after task1!
[2022-08-06 22:23:38,783] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:23:38,812] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=second_task, execution_date=20220204T000000, start_date=20220806T222338, end_date=20220806T222338
[2022-08-06 22:23:38,834] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:23:38,875] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
