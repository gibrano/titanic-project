[2022-08-06 19:36:10,622] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [queued]>
[2022-08-06 19:36:10,640] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [queued]>
[2022-08-06 19:36:10,640] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:36:10,640] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:36:10,641] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:36:10,662] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-16 00:00:00+00:00
[2022-08-06 19:36:10,669] {standard_task_runner.py:52} INFO - Started process 264 to run task
[2022-08-06 19:36:10,672] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-16T00:00:00+00:00', '--job-id', '56', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmph6a59zs_', '--error-file', '/tmp/tmp5ccb53xh']
[2022-08-06 19:36:10,673] {standard_task_runner.py:80} INFO - Job 56: Subtask thrid_task
[2022-08-06 19:36:10,765] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:36:10,897] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-16T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-16T00:00:00+00:00
[2022-08-06 19:36:10,898] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:36:10,899] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 19:36:10,926] {subprocess.py:85} INFO - Output:
[2022-08-06 19:36:10,926] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 19:36:10,928] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:36:10,977] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210816T000000, start_date=20220806T193610, end_date=20220806T193610
[2022-08-06 19:36:11,020] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:36:11,063] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:50:06,041] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [queued]>
[2022-08-06 21:50:06,057] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [queued]>
[2022-08-06 21:50:06,058] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:50:06,058] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:50:06,058] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:50:06,077] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-16 00:00:00+00:00
[2022-08-06 21:50:06,085] {standard_task_runner.py:52} INFO - Started process 458 to run task
[2022-08-06 21:50:06,088] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-16T00:00:00+00:00', '--job-id', '60', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpdmzqempd', '--error-file', '/tmp/tmpcnsl5js6']
[2022-08-06 21:50:06,089] {standard_task_runner.py:80} INFO - Job 60: Subtask thrid_task
[2022-08-06 21:50:06,173] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:50:06,280] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-16T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-16T00:00:00+00:00
[2022-08-06 21:50:06,281] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:50:06,282] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:50:06,299] {subprocess.py:85} INFO - Output:
[2022-08-06 21:50:06,301] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:50:06,301] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:50:06,374] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210816T000000, start_date=20220806T215006, end_date=20220806T215006
[2022-08-06 21:50:06,420] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:50:06,468] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:55:34,498] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [queued]>
[2022-08-06 21:55:34,514] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [queued]>
[2022-08-06 21:55:34,514] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:55:34,514] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:55:34,514] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:55:34,530] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-16 00:00:00+00:00
[2022-08-06 21:55:34,536] {standard_task_runner.py:52} INFO - Started process 248 to run task
[2022-08-06 21:55:34,538] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-16T00:00:00+00:00', '--job-id', '56', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpejhb9okf', '--error-file', '/tmp/tmp3npf9eb1']
[2022-08-06 21:55:34,539] {standard_task_runner.py:80} INFO - Job 56: Subtask thrid_task
[2022-08-06 21:55:34,598] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:55:34,666] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-16T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-16T00:00:00+00:00
[2022-08-06 21:55:34,667] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:55:34,667] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:55:34,679] {subprocess.py:85} INFO - Output:
[2022-08-06 21:55:34,680] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:55:34,680] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:55:34,708] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210816T000000, start_date=20220806T215534, end_date=20220806T215534
[2022-08-06 21:55:34,750] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:55:34,775] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:10:35,789] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [queued]>
[2022-08-06 22:10:35,804] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [queued]>
[2022-08-06 22:10:35,804] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:10:35,804] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:10:35,804] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:10:35,822] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-16 00:00:00+00:00
[2022-08-06 22:10:35,830] {standard_task_runner.py:52} INFO - Started process 254 to run task
[2022-08-06 22:10:35,832] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-16T00:00:00+00:00', '--job-id', '58', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmphxk_1btb', '--error-file', '/tmp/tmpkl5bk2si']
[2022-08-06 22:10:35,833] {standard_task_runner.py:80} INFO - Job 58: Subtask thrid_task
[2022-08-06 22:10:35,918] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:10:36,035] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-16T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-16T00:00:00+00:00
[2022-08-06 22:10:36,036] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:10:36,037] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:10:36,053] {subprocess.py:85} INFO - Output:
[2022-08-06 22:10:36,055] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:10:36,055] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:10:36,126] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210816T000000, start_date=20220806T221035, end_date=20220806T221036
[2022-08-06 22:10:36,206] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:10:36,259] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:18:23,255] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [queued]>
[2022-08-06 22:18:23,271] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [queued]>
[2022-08-06 22:18:23,272] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:18:23,272] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:18:23,272] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:18:23,287] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-16 00:00:00+00:00
[2022-08-06 22:18:23,294] {standard_task_runner.py:52} INFO - Started process 271 to run task
[2022-08-06 22:18:23,297] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-16T00:00:00+00:00', '--job-id', '55', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp333njveg', '--error-file', '/tmp/tmpvnuujdfr']
[2022-08-06 22:18:23,297] {standard_task_runner.py:80} INFO - Job 55: Subtask thrid_task
[2022-08-06 22:18:23,383] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [running]> on host ed53bde1c44a
[2022-08-06 22:18:23,480] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-16T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-16T00:00:00+00:00
[2022-08-06 22:18:23,481] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:18:23,481] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:18:23,497] {subprocess.py:85} INFO - Output:
[2022-08-06 22:18:23,499] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:18:23,500] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:18:23,578] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210816T000000, start_date=20220806T221823, end_date=20220806T221823
[2022-08-06 22:18:23,630] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:18:23,676] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:21:57,065] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [queued]>
[2022-08-06 22:21:57,079] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [queued]>
[2022-08-06 22:21:57,079] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:21:57,079] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:21:57,079] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:21:57,097] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-16 00:00:00+00:00
[2022-08-06 22:21:57,120] {standard_task_runner.py:52} INFO - Started process 313 to run task
[2022-08-06 22:21:57,125] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-16T00:00:00+00:00', '--job-id', '58', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpw_1ybpq6', '--error-file', '/tmp/tmpwieb0bc5']
[2022-08-06 22:21:57,125] {standard_task_runner.py:80} INFO - Job 58: Subtask thrid_task
[2022-08-06 22:21:57,218] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-16T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:21:57,333] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-16T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-16T00:00:00+00:00
[2022-08-06 22:21:57,334] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:21:57,335] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:21:57,352] {subprocess.py:85} INFO - Output:
[2022-08-06 22:21:57,353] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:21:57,354] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:21:57,431] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210816T000000, start_date=20220806T222157, end_date=20220806T222157
[2022-08-06 22:21:57,457] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:21:57,500] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
