[2022-08-06 19:37:46,569] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [queued]>
[2022-08-06 19:37:46,585] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [queued]>
[2022-08-06 19:37:46,585] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:46,585] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:37:46,585] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:37:46,606] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-16 00:00:00+00:00
[2022-08-06 19:37:46,614] {standard_task_runner.py:52} INFO - Started process 1712 to run task
[2022-08-06 19:37:46,617] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-16T00:00:00+00:00', '--job-id', '516', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpcieh7e2e', '--error-file', '/tmp/tmp3wfe43ep']
[2022-08-06 19:37:46,617] {standard_task_runner.py:80} INFO - Job 516: Subtask thrid_task
[2022-08-06 19:37:46,703] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:37:46,820] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-16T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-16T00:00:00+00:00
[2022-08-06 19:37:46,821] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:37:46,821] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 19:37:46,840] {subprocess.py:85} INFO - Output:
[2022-08-06 19:37:46,843] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 19:37:46,843] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:37:46,884] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220116T000000, start_date=20220806T193746, end_date=20220806T193746
[2022-08-06 19:37:46,909] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:37:46,956] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:51:40,701] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [queued]>
[2022-08-06 21:51:40,714] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [queued]>
[2022-08-06 21:51:40,714] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:40,714] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:51:40,714] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:51:40,728] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-16 00:00:00+00:00
[2022-08-06 21:51:40,734] {standard_task_runner.py:52} INFO - Started process 1902 to run task
[2022-08-06 21:51:40,736] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-16T00:00:00+00:00', '--job-id', '516', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpg963nsdk', '--error-file', '/tmp/tmpli46ti5f']
[2022-08-06 21:51:40,736] {standard_task_runner.py:80} INFO - Job 516: Subtask thrid_task
[2022-08-06 21:51:40,836] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:51:40,958] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-16T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-16T00:00:00+00:00
[2022-08-06 21:51:40,959] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:51:40,959] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:51:40,975] {subprocess.py:85} INFO - Output:
[2022-08-06 21:51:40,977] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:51:40,978] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:51:41,025] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220116T000000, start_date=20220806T215140, end_date=20220806T215141
[2022-08-06 21:51:41,068] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:51:41,146] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:57:04,636] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [queued]>
[2022-08-06 21:57:04,654] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [queued]>
[2022-08-06 21:57:04,654] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:04,654] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:57:04,654] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:57:04,676] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-16 00:00:00+00:00
[2022-08-06 21:57:04,684] {standard_task_runner.py:52} INFO - Started process 1708 to run task
[2022-08-06 21:57:04,687] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-16T00:00:00+00:00', '--job-id', '522', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmplaonz_01', '--error-file', '/tmp/tmpliv66agq']
[2022-08-06 21:57:04,688] {standard_task_runner.py:80} INFO - Job 522: Subtask thrid_task
[2022-08-06 21:57:04,794] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:57:04,912] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-16T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-16T00:00:00+00:00
[2022-08-06 21:57:04,913] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:57:04,914] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:57:04,928] {subprocess.py:85} INFO - Output:
[2022-08-06 21:57:04,930] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:57:04,930] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:57:04,971] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220116T000000, start_date=20220806T215704, end_date=20220806T215704
[2022-08-06 21:57:05,021] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:57:05,080] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:12:05,403] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [queued]>
[2022-08-06 22:12:05,417] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [queued]>
[2022-08-06 22:12:05,417] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:05,418] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:12:05,418] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:12:05,435] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-16 00:00:00+00:00
[2022-08-06 22:12:05,441] {standard_task_runner.py:52} INFO - Started process 1707 to run task
[2022-08-06 22:12:05,444] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-16T00:00:00+00:00', '--job-id', '517', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpbjdke5tj', '--error-file', '/tmp/tmp5uffg1fv']
[2022-08-06 22:12:05,445] {standard_task_runner.py:80} INFO - Job 517: Subtask thrid_task
[2022-08-06 22:12:05,515] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:12:05,623] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-16T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-16T00:00:00+00:00
[2022-08-06 22:12:05,624] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:12:05,625] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:12:05,641] {subprocess.py:85} INFO - Output:
[2022-08-06 22:12:05,643] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:12:05,643] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:12:05,700] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220116T000000, start_date=20220806T221205, end_date=20220806T221205
[2022-08-06 22:12:05,736] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:12:05,772] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:23:25,728] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [queued]>
[2022-08-06 22:23:25,747] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [queued]>
[2022-08-06 22:23:25,747] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:25,747] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:23:25,747] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:23:25,766] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2022-01-16 00:00:00+00:00
[2022-08-06 22:23:25,772] {standard_task_runner.py:52} INFO - Started process 1757 to run task
[2022-08-06 22:23:25,775] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2022-01-16T00:00:00+00:00', '--job-id', '519', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp3attngw7', '--error-file', '/tmp/tmp2vbxcy3v']
[2022-08-06 22:23:25,775] {standard_task_runner.py:80} INFO - Job 519: Subtask thrid_task
[2022-08-06 22:23:25,842] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2022-01-16T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:23:25,929] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2022-01-16T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-01-16T00:00:00+00:00
[2022-08-06 22:23:25,929] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:23:25,930] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:23:25,941] {subprocess.py:85} INFO - Output:
[2022-08-06 22:23:25,942] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:23:25,942] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:23:25,970] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20220116T000000, start_date=20220806T222325, end_date=20220806T222325
[2022-08-06 22:23:25,986] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:23:26,016] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
