[2022-08-06 19:36:10,622] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [queued]>
[2022-08-06 19:36:10,639] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [queued]>
[2022-08-06 19:36:10,639] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:36:10,639] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 19:36:10,640] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 19:36:10,659] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-15 00:00:00+00:00
[2022-08-06 19:36:10,666] {standard_task_runner.py:52} INFO - Started process 263 to run task
[2022-08-06 19:36:10,669] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-15T00:00:00+00:00', '--job-id', '57', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp5rlfjnuj', '--error-file', '/tmp/tmpqz7aqza6']
[2022-08-06 19:36:10,669] {standard_task_runner.py:80} INFO - Job 57: Subtask thrid_task
[2022-08-06 19:36:10,783] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [running]> on host b29c168c1666
[2022-08-06 19:36:10,933] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-15T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-15T00:00:00+00:00
[2022-08-06 19:36:10,934] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 19:36:10,935] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 19:36:10,953] {subprocess.py:85} INFO - Output:
[2022-08-06 19:36:10,954] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 19:36:10,955] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 19:36:11,007] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210815T000000, start_date=20220806T193610, end_date=20220806T193611
[2022-08-06 19:36:11,043] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 19:36:11,082] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:50:05,992] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [queued]>
[2022-08-06 21:50:06,006] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [queued]>
[2022-08-06 21:50:06,006] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:50:06,006] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:50:06,007] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:50:06,021] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-15 00:00:00+00:00
[2022-08-06 21:50:06,028] {standard_task_runner.py:52} INFO - Started process 453 to run task
[2022-08-06 21:50:06,032] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-15T00:00:00+00:00', '--job-id', '56', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpdpbly4eh', '--error-file', '/tmp/tmpff41dacc']
[2022-08-06 21:50:06,032] {standard_task_runner.py:80} INFO - Job 56: Subtask thrid_task
[2022-08-06 21:50:06,117] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [running]> on host c3f731879890
[2022-08-06 21:50:06,229] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-15T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-15T00:00:00+00:00
[2022-08-06 21:50:06,230] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:50:06,230] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:50:06,248] {subprocess.py:85} INFO - Output:
[2022-08-06 21:50:06,250] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:50:06,250] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:50:06,291] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210815T000000, start_date=20220806T215005, end_date=20220806T215006
[2022-08-06 21:50:06,322] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:50:06,387] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 21:55:34,343] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [queued]>
[2022-08-06 21:55:34,360] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [queued]>
[2022-08-06 21:55:34,360] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:55:34,361] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 21:55:34,361] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 21:55:34,378] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-15 00:00:00+00:00
[2022-08-06 21:55:34,384] {standard_task_runner.py:52} INFO - Started process 246 to run task
[2022-08-06 21:55:34,387] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-15T00:00:00+00:00', '--job-id', '54', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmps169_91h', '--error-file', '/tmp/tmpkc60ujms']
[2022-08-06 21:55:34,387] {standard_task_runner.py:80} INFO - Job 54: Subtask thrid_task
[2022-08-06 21:55:34,457] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [running]> on host bc7e154a4fdd
[2022-08-06 21:55:34,544] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-15T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-15T00:00:00+00:00
[2022-08-06 21:55:34,545] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 21:55:34,546] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 21:55:34,560] {subprocess.py:85} INFO - Output:
[2022-08-06 21:55:34,561] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 21:55:34,562] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 21:55:34,593] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210815T000000, start_date=20220806T215534, end_date=20220806T215534
[2022-08-06 21:55:34,638] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 21:55:34,666] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:10:35,818] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [queued]>
[2022-08-06 22:10:35,834] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [queued]>
[2022-08-06 22:10:35,834] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:10:35,834] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:10:35,834] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:10:35,861] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-15 00:00:00+00:00
[2022-08-06 22:10:35,873] {standard_task_runner.py:52} INFO - Started process 255 to run task
[2022-08-06 22:10:35,877] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-15T00:00:00+00:00', '--job-id', '59', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpgzzosgzc', '--error-file', '/tmp/tmp0bki7qfo']
[2022-08-06 22:10:35,877] {standard_task_runner.py:80} INFO - Job 59: Subtask thrid_task
[2022-08-06 22:10:35,969] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [running]> on host 1250c3b659cd
[2022-08-06 22:10:36,080] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-15T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-15T00:00:00+00:00
[2022-08-06 22:10:36,081] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:10:36,081] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:10:36,094] {subprocess.py:85} INFO - Output:
[2022-08-06 22:10:36,095] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:10:36,095] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:10:36,143] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210815T000000, start_date=20220806T221035, end_date=20220806T221036
[2022-08-06 22:10:36,211] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:10:36,256] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:18:23,256] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [queued]>
[2022-08-06 22:18:23,269] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [queued]>
[2022-08-06 22:18:23,269] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:18:23,269] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:18:23,269] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:18:23,283] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-15 00:00:00+00:00
[2022-08-06 22:18:23,290] {standard_task_runner.py:52} INFO - Started process 270 to run task
[2022-08-06 22:18:23,292] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-15T00:00:00+00:00', '--job-id', '57', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmps0y_2vrb', '--error-file', '/tmp/tmpq7zw6q46']
[2022-08-06 22:18:23,293] {standard_task_runner.py:80} INFO - Job 57: Subtask thrid_task
[2022-08-06 22:18:23,370] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [running]> on host ed53bde1c44a
[2022-08-06 22:18:23,479] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-15T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-15T00:00:00+00:00
[2022-08-06 22:18:23,480] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:18:23,481] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:18:23,497] {subprocess.py:85} INFO - Output:
[2022-08-06 22:18:23,498] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:18:23,499] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:18:23,577] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210815T000000, start_date=20220806T221823, end_date=20220806T221823
[2022-08-06 22:18:23,625] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:18:23,669] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-08-06 22:21:56,801] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [queued]>
[2022-08-06 22:21:56,814] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [queued]>
[2022-08-06 22:21:56,815] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:21:56,815] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-06 22:21:56,815] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-06 22:21:56,838] {taskinstance.py:1397} INFO - Executing <Task(BashOperator): thrid_task> on 2021-08-15 00:00:00+00:00
[2022-08-06 22:21:56,846] {standard_task_runner.py:52} INFO - Started process 304 to run task
[2022-08-06 22:21:56,849] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'our_first_dag_v5', 'thrid_task', 'scheduled__2021-08-15T00:00:00+00:00', '--job-id', '55', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp5tiks_q7', '--error-file', '/tmp/tmpayf9hyvi']
[2022-08-06 22:21:56,849] {standard_task_runner.py:80} INFO - Job 55: Subtask thrid_task
[2022-08-06 22:21:56,941] {task_command.py:371} INFO - Running <TaskInstance: our_first_dag_v5.thrid_task scheduled__2021-08-15T00:00:00+00:00 [running]> on host b215076695c3
[2022-08-06 22:21:57,046] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=coder2j
AIRFLOW_CTX_DAG_ID=our_first_dag_v5
AIRFLOW_CTX_TASK_ID=thrid_task
AIRFLOW_CTX_EXECUTION_DATE=2021-08-15T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-08-15T00:00:00+00:00
[2022-08-06 22:21:57,047] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-08-06 22:21:57,048] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'echo hey, I am task3 and will be running after task1 at the same time as task2!']
[2022-08-06 22:21:57,062] {subprocess.py:85} INFO - Output:
[2022-08-06 22:21:57,064] {subprocess.py:92} INFO - hey, I am task3 and will be running after task1 at the same time as task2!
[2022-08-06 22:21:57,064] {subprocess.py:96} INFO - Command exited with return code 0
[2022-08-06 22:21:57,141] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=our_first_dag_v5, task_id=thrid_task, execution_date=20210815T000000, start_date=20220806T222156, end_date=20220806T222157
[2022-08-06 22:21:57,182] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-08-06 22:21:57,229] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
